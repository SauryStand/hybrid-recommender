{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":13,"outputs":[{"output_type":"stream","text":"/kaggle/input/the-movies-dataset/links.csv\n/kaggle/input/the-movies-dataset/ratings_small.csv\n/kaggle/input/the-movies-dataset/links_small.csv\n/kaggle/input/the-movies-dataset/credits.csv\n/kaggle/input/the-movies-dataset/ratings.csv\n/kaggle/input/the-movies-dataset/movies_metadata.csv\n/kaggle/input/the-movies-dataset/keywords.csv\n/kaggle/input/wsdm-kkbox/songs.csv\n/kaggle/input/wsdm-kkbox/members.csv\n/kaggle/input/wsdm-kkbox/train.csv\n/kaggle/input/wsdm-kkbox/test.csv\n/kaggle/input/wsdm-kkbox/song_extra_info.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import csr_matrix\nfrom sklearn.neighbors import NearestNeighbors\nfrom fuzzywuzzy import fuzz\nfrom ast import literal_eval\nfrom surprise import SVD, SVDpp, KNNBasic\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate,train_test_split, GridSearchCV\nfrom surprise import NormalPredictor\nfrom surprise import Reader\n\nimport re \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport nltk\n\nnltk.download('stopwords')","execution_count":14,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = pd.read_csv('/kaggle/input/the-movies-dataset/ratings.csv')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_array = ratings['rating'].unique()\nmax_rating = np.amax( ratings_array )\nmin_rating = np.amin( ratings_array )\nprint( ratings_array )","execution_count":16,"outputs":[{"output_type":"stream","text":"[1.  4.5 5.  4.  3.5 2.5 0.5 3.  2.  1.5]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_data = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_data['genres'] = m_data['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_data['genres_str']= m_data['genres'].apply(lambda x: \",\".join(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_movieId( movie_name ):\n    \"\"\"\n    return the movieId which is corresponding to the movie name\n\n    Parameters\n    ----------\n    movie_name: string, the name of the movie w/ or w/o the year\n\n    Return\n    ------\n    the movieId\n    \"\"\"\n    # If luckily the movie name is 100% equal to a name writen in the database,\n    # then return the id corresponding to the name.\n    # Or...we need to consider the similarity between strings \n    if (movie_name in movie_map):\n        return movie_map[movie_name]\n    else:\n        similar = []\n        for title, movie_id in movie_map.items():\n            ratio = fuzz.ratio(title.lower(), movie_name.lower())\n            if ( ratio >= 60):\n                similar.append( (title, movie_id, ratio ) )\n        if (len(similar) == 0):\n            print(\"Oh! This movie does not exist in the database.\")\n        else:\n            match_item = sorted( similar , key=lambda x: x[2] )[::-1]\n            print( \"The matched item might be:\", match_item[0][0], \", ratio=\",match_item[0][2] )\n            return match_item[0][1]","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenizer(text):\n    torkenized = [PorterStemmer().stem(word).lower() for word in text.split('|') if word not in stopwords.words('english')]\n    return torkenized","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfid=TfidfVectorizer(analyzer='word', tokenizer=tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_matrix = tfid.fit_transform(m_data['genres_str'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cos_sim = cosine_similarity(tfidf_matrix,tfidf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cos_sim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tfidf_matrix.shape)\nprint(cos_sim.shape)\nprint(m_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['userId','movieId', 'rating']\nreader = Reader(rating_scale=(min_rating, max_rating))\ndata = Dataset.load_from_df(ratings[features], reader)\nfrom surprise.model_selection import train_test_split\ntrainset, testset = train_test_split(data, test_size=.25)\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n              'reg_all': [0.4, 0.6]}\n#gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\nsvd = SVD()\n#consume too much memory\n#cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gs.fit(data)\n# print(gs.best_score['rmse'])\n# print(gs.best_params['rmse'])\n# best_params = gs.best_params['rmse']\n# model_svd = gs.best_estimator['rmse']\n# #没有做数据集划分\n# model_svd.fit(data.build_full_trainset())","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise.model_selection import train_test_split\ntrainset, testset = train_test_split(data, test_size=.25)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_rating_from_prediction( prediction, ratings_array ):\n    \"\"\"\n    return the closest rating number to the prediction value\n\n    Parameters\n    ----------\n    prediction: float, the prediction value from the model\n\n    ratings_array: the 1D array of the discrete rating number\n\n    Return\n    ------\n    the rating number corresponding to the prediction value\n    \"\"\"\n    rating = ratings_array[ np.argmin( [ np.abs(item - prediction) for item in ratings_array ] ) ]\n    return rating","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = data.build_full_trainset()\nsvd.fit(trainset)\n","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fe8c0749e90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = svd.test(testset)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del trainset\ndel testset","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import accuracy\naccuracy.rmse(predictions)","execution_count":30,"outputs":[{"output_type":"stream","text":"RMSE: 0.6791\n","name":"stdout"},{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"0.6790566411936375"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise.model_selection import KFold\n\n\nkf = KFold(n_splits=5)\n\nalgo = SVD()\n\nfor trainset, testset in kf.split(data):\n\n    # 训练并测试算法\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # 计算并打印 RMSE（均方根误差，Root Mean Squared Error）\n    accuracy.rmse(predictions, verbose=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}